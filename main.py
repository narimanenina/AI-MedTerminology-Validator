import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import re
from pydub import AudioSegment
from streamlit_mic_recorder import mic_recorder
from datetime import datetime

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ… (Ø¨Ø±ÙˆØ­ Ø·Ø¨ÙŠØ© ÙˆØªÙ‚Ù†ÙŠØ©) ---
st.set_page_config(page_title="MedSpeak AI | Web3 Medical Agent", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    .reward-card { 
        padding: 20px; 
        border-radius: 15px; 
        background: linear-gradient(135deg, #007bff, #6610f2); 
        color: white;
        text-align: center;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© ÙˆØ§Ù„Ù…ÙƒØ§ÙØ¢Øª ---
@st.cache_data
def load_medical_db():
    # Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù…Ù„Ù Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©
    data = {
        'term': ['Otorhinolaryngology', 'Myocardial Infarction', 'Anaphylaxis', 'Gastroenteritis', 'Hypercholesterolemia'],
        'ipa': ['oÊŠtoÊŠËŒraÉªnoÊŠ', 'ËŒmaÉªÉ™ËˆkÉ‘ËrdiÉ™l', 'ËŒÃ¦nÉ™fÉªËˆlÃ¦ksÉªs', 'ËŒÉ¡Ã¦stroÊŠËŒÉ›ntÉ™ËˆraÉªtÉªs', 'ËŒhaÉªpÉ™rhÉ™ËŒlÉ›stÉ™rÉ™'],
        'difficulty': ['Hard', 'Medium', 'Medium', 'Medium', 'Hard'],
        'reward': [50, 20, 15, 15, 45]
    }
    return pd.DataFrame(data)

def save_medical_record(address, term, accuracy, reward):
    # Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø¹Ù„Ù‰ Ø£Ù†Ù‡ "Transaction" Ù…Ø­Ø§ÙƒÙŠØ© ÙÙŠ Ø§Ù„Ù€ Web3
    db_file = 'medical_onchain_records.xlsx'
    new_tx = {
        'Timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
        'Wallet_Address': address,
        'Medical_Term': term,
        'Accuracy': f"{accuracy}%",
        'Status': 'Verified & Rewarded',
        'Reward_Amount': f"{reward} $SURGE"
    }
    df_new = pd.DataFrame([new_tx])
    if os.path.exists(db_file):
        df_existing = pd.read_excel(db_file)
        df_final = pd.concat([df_existing, df_new], ignore_index=True)
    else:
        df_final = df_new
    df_final.to_excel(db_file, index=False)

# --- 3. Ù…Ø­Ø§ÙƒØ§Ø© Ø±Ø¨Ø· Ø§Ù„Ù…Ø­ÙØ¸Ø© (Web3 Integration) ---
def connect_wallet():
    st.session_state['connected'] = True
    st.session_state['address'] = "0x71C941...392a"
    st.session_state['balance'] = 1250.0

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ©º MedSpeak AI")
st.subheader("Smart Medical Pronunciation & Web3 Rewards")

# Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
with st.sidebar:
    st.header("ğŸŒ Web3 Identity")
    if 'connected' not in st.session_state:
        if st.button("Connect Wallet (Surge)"):
            connect_wallet()
            st.rerun()
    else:
        st.markdown(f"""
        <div class='reward-card'>
            <small>Connected Wallet</small><br>
            <strong>{st.session_state['address']}</strong><br><br>
            <small>Current Balance</small><br>
            <h3>{st.session_state['balance']} $SURGE</h3>
        </div>
        """, unsafe_allow_html=True)

# Ù…Ù†Ø·Ù‚Ø© Ù…Ù…Ø§Ø±Ø³Ø© Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª
df_med = load_medical_db()
col_a, col_b = st.columns([1, 1])

with col_a:
    st.info("ğŸ’¡ Ø§Ø®ØªØ± Ù…ØµØ·Ù„Ø­Ø§Ù‹ Ø·Ø¨ÙŠØ§Ù‹ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡ ÙˆÙƒØ³Ø¨ Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª.")
    target_term = st.selectbox("Select Medical Term:", df_med['term'].tolist())
    term_data = df_med[df_med['term'] == target_term].iloc[0]
    
    st.markdown(f"""
    **Phonetic Guide:** `/{term_data['ipa']}/`  
    **Difficulty:** `{term_data['difficulty']}`  
    **Potential Reward:** `{term_data['reward']} $SURGE`
    """)

with col_b:
    st.subheader("ğŸ¤ Voice Recording")
    record = mic_recorder(start_prompt="Start Recording", stop_prompt="Stop to Verify", key='med_recorder')
    
    if record:
        st.audio(record['bytes'])
        try:
            with st.spinner("Analyzing Medical Phonemes..."):
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª
                audio_segment = AudioSegment.from_file(io.BytesIO(record['bytes']))
                wav_io = io.BytesIO()
                audio_segment.export(wav_io, format="wav")
                wav_io.seek(0)
                
                r = sr.Recognizer()
                with sr.AudioFile(wav_io) as source:
                    audio_content = r.record(source)
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©
                    ai_text = r.recognize_google(audio_content, language="en-US")
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
                accuracy = round(difflib.SequenceMatcher(None, target_term.lower(), ai_text.lower()).ratio() * 100, 1)
                
                st.metric("Pronunciation Accuracy", f"{accuracy}%")
                
                if accuracy >= 85:
                    st.balloons()
                    st.success(f"Verified! You earned {term_data['reward']} $SURGE")
                    if 'connected' in st.session_state:
                        save_medical_record(st.session_state['address'], target_term, accuracy, term_data['reward'])
                        st.session_state['balance'] += term_data['reward']
                else:
                    st.warning(f"Heard: '{ai_text}'. Accuracy too low for reward. Try again!")
                    
        except Exception as e:
            st.error("AI could not process the audio. Please speak clearly.")

# --- Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Ø´ÙØ§ÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) ---
st.divider()
if st.checkbox("ğŸ” View On-Chain Learning Logs"):
    if os.path.exists('medical_onchain_records.xlsx'):
        logs = pd.read_excel('medical_onchain_records.xlsx')
        st.dataframe(logs, use_container_width=True)
    else:
        st.write("No transactions recorded yet.")













