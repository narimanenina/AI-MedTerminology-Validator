import streamlit as st
import pandas as pd
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
import io
import difflib

# --- 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© ---
@st.cache_data
def load_medical_data():
    # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù medical_terms.csv Ø§Ù„Ø°ÙŠ Ø£Ù†Ø´Ø£Ù†Ø§Ù‡ Ø³Ø§Ø¨Ù‚Ø§Ù‹
    try:
        return pd.read_csv('medical_terms.csv')
    except:
        return pd.DataFrame({
            'term': ['Otorhinolaryngology', 'Anaphylaxis', 'Myocardial Infarction'],
            'ipa': ['oÊŠtoÊŠËŒraÉªnoÊŠ', 'ËŒÃ¦nÉ™fÉªËˆlÃ¦ksÉªs', 'ËŒmaÉªÉ™ËˆkÉ‘ËrdiÉ™l'],
            'difficulty': ['Hard', 'Medium', 'Medium'],
            'reward_surge': [50, 15, 20]
        })

df_medical = load_medical_data()

# --- 2. Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (Speech to Text) ---
def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    audio_file = io.BytesIO(audio_bytes)
    with sr.AudioFile(audio_file) as source:
        audio_data = r.record(source)
        try:
            # Ù†Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø·Ø¨ÙŠØ©
            text = r.recognize_google(audio_data, language="en-US")
            return text
        except:
            return None

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("ğŸ©º MedSpeak AI: Voice Practice")

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØµØ·Ù„Ø­
selected_term = st.selectbox("Select a medical term to practice:", df_medical['term'].tolist())
term_info = df_medical[df_medical['term'] == selected_term].iloc[0]

st.info(f"Target: **{selected_term}** | Expected IPA: `/{term_info['ipa']}/`")

# --- 4. Ø¬Ø²Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª ---
st.write("Click the mic and say the term clearly:")
audio_record = mic_recorder(
    start_prompt="âºï¸ Start Recording",
    stop_prompt="â¹ï¸ Stop & Analyze",
    key='recorder'
)

if audio_record:
    # 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„ Ø¥Ù„Ù‰ Ù†Øµ
    with st.spinner("Analyzing your voice..."):
        spoken_text = transcribe_audio(audio_record['bytes'])
        
        if spoken_text:
            st.write(f"ğŸ‘‚ I heard: **'{spoken_text}'**")
            
            # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            accuracy = round(difflib.SequenceMatcher(None, selected_term.lower(), spoken_text.lower()).ratio() * 100, 1)
            
            # 3. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØ§Ù„Ù…ÙƒØ§ÙØ£Ø©
            st.metric("Accuracy Score", f"{accuracy}%")
            
            if accuracy >= 85:
                st.balloons()
                st.success(f"Excellent! You've earned {term_info['reward_surge']} $SURGE tokens.")
                # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±ØµÙŠØ¯ ÙÙŠ Ø§Ù„Ù…Ø­ÙØ¸Ø©
            else:
                st.warning("Keep practicing! Try to emphasize each syllable.")
        else:
            st.error("Could not recognize the audio. Please speak louder and clearer.")

# --- 5. Ø±Ø¨Ø· Ø§Ù„Ù…Ø­ÙØ¸Ø© (Web3 Simulation) ---
with st.sidebar:
    st.header("Web3 Wallet")
    if 'balance' not in st.session_state:
        st.session_state['balance'] = 100.0
    st.metric("Current Balance", f"{st.session_state['balance']} $SURGE")
    st.caption("Data is hashed and stored on-chain for privacy.")

















